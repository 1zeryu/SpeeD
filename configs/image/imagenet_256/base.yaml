# model configuration
num_classes: 1000
image_size: 256

# terminal information: epoch > epochs or train_steps > max_iter
model:
  _target_: speedit.networks.dit.DiT_XL_2
  num_classes: ${num_classes}

diffusion:
  _target_: speedit.diffusion.iddpm.IDDPM
  timestep_respacing: ""
  faster: true

vae:
  _target_: diffusers.models.AutoencoderKL.from_pretrained
  pretrained_model_name_or_path: "transformers/sd-vae-ft-ema"


inference:
  diffusion:
    timestep_respacing: '250'
  guidance_scale: 3.8
  per_proc_batch_size: 4
  num_samples: 20


sample:
  guidance_scale: 3.8
  diffusion:
    timestep_respacing: '250'
  sample_classes: [207, 360]

optimizer:
  _target_: torch.optim.AdamW
  lr: 0.0001
  weight_decay: 0


data:
  _target_:
  dataset:
    _target_: speedit.dataset.image.image_dataest
    root: /home/kwang/datasets/imagenet/train
    image_size: ${image_size}

  batch_size: 7
  num_workers: 4


epoch: 1400
